{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d7cc342",
   "metadata": {},
   "source": [
    "### Grab influx of Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5968cbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import timedelta\n",
    "### Todo store number of comments per spike \n",
    "### Todo store the comments\n",
    "\n",
    "\n",
    "# --- Parameters ---\n",
    "csv_file = \"USCvsNois_video.csv\"  # your csv\n",
    "window_minutes = 2\n",
    "threshold_multiplier = 2.0  # e.g., spike = 2x baseline\n",
    "slide_seconds = 30          # slide every 30 seconds\n",
    "\n",
    "# --- Load ---\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# --- Robust timestamp parsing (supports mm:ss, hh:mm:ss, fractional seconds, large mins/hours) ---\n",
    "def _parse_to_seconds(val):\n",
    "    s = str(val).strip()\n",
    "    if not s or s.lower() in {\"nan\", \"nat\"}:\n",
    "        return np.nan\n",
    "\n",
    "    # Remove common noise around AM/PM while keeping numbers/colons/dots intact\n",
    "    s_clean = re.sub(r\"\\s+\", \"\", s)\n",
    "    s_clean = re.sub(r\"(?i)\\b(am|pm)\\b\", \"\", s_clean)\n",
    "\n",
    "    # hh:mm:ss(.frac)\n",
    "    m_hms = re.match(r\"^(?P<h>\\d+):(?P<m>\\d{1,2}):(?P<s>\\d{1,2}(?:\\.\\d+)?)$\", s_clean)\n",
    "    if m_hms:\n",
    "        h = int(m_hms.group(\"h\"))\n",
    "        m = int(m_hms.group(\"m\"))\n",
    "        sec = float(m_hms.group(\"s\"))\n",
    "        return h * 3600 + m * 60 + sec\n",
    "\n",
    "    # mm:ss(.frac) — treat first as minutes (can exceed 59)\n",
    "    m_ms = re.match(r\"^(?P<m>\\d+):(?P<s>\\d{1,2}(?:\\.\\d+)?)$\", s_clean)\n",
    "    if m_ms:\n",
    "        m = int(m_ms.group(\"m\"))\n",
    "        sec = float(m_ms.group(\"s\"))\n",
    "        return m * 60 + sec\n",
    "\n",
    "    # hh:mm (no seconds) — interpret as hours:minutes\n",
    "    m_hm = re.match(r\"^(?P<h>\\d+):(?P<m>\\d{1,2})$\", s_clean)\n",
    "    if m_hm:\n",
    "        h = int(m_hm.group(\"h\"))\n",
    "        m = int(m_hm.group(\"m\"))\n",
    "        return h * 3600 + m * 60\n",
    "\n",
    "    # Plain number -> seconds\n",
    "    m_num = re.match(r\"^\\d+(?:\\.\\d+)?$\", s_clean)\n",
    "    if m_num:\n",
    "        return float(s_clean)\n",
    "\n",
    "    # Fallback: try pandas datetime and take time-of-day\n",
    "    try:\n",
    "        dt = pd.to_datetime(s_clean, errors=\"raise\")\n",
    "        return (\n",
    "            dt.hour * 3600\n",
    "            + dt.minute * 60\n",
    "            + dt.second\n",
    "            + dt.microsecond / 1e6\n",
    "        )\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# Vectorized parse\n",
    "secs = pd.Series(( _parse_to_seconds(v) for v in df[\"timestamp\"] ), index=df.index, dtype=\"float64\")\n",
    "parsed_ok = secs.notna().sum()\n",
    "#check if a timestap fails\n",
    "parsed_fail = secs.isna().sum()\n",
    "if parsed_fail:\n",
    "    print(f\"Warning: {parsed_fail} timestamp(s) could not be parsed. Showing up to 10 examples:\")\n",
    "    bad_idx = secs[secs.isna()].index[:10]\n",
    "    print(df.loc[bad_idx, \"timestamp\"].to_string(index=False))\n",
    "\n",
    "df[\"timestamp\"] = pd.to_timedelta(secs, unit=\"s\", errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"timestamp\"]).copy()\n",
    "\n",
    "# Sort by time\n",
    "df = df.sort_values(\"timestamp\")\n",
    "\n",
    "#check if all times are bad\n",
    "if df.empty:\n",
    "    raise ValueError(\"No valid timestamps left after parsing. Please inspect the CSV format.\")\n",
    "\n",
    "# --- Baseline engagement ---\n",
    "# Use elapsed duration = max - min (not just max)\n",
    "elapsed = (df[\"timestamp\"].max() - df[\"timestamp\"].min()).total_seconds() / 60.0\n",
    "if elapsed <= 0:\n",
    "    raise ValueError(\"Non-positive elapsed time computed. Are all timestamps the same?\")\n",
    "avg_comments_per_minute = len(df) / elapsed\n",
    "print(f\"Parsed timestamps: {parsed_ok}, Dropped: {parsed_fail}\")\n",
    "print(f\"Average comments per minute: {avg_comments_per_minute:.2f}\")\n",
    "\n",
    "# --- Sliding window spike detection (fast) ---\n",
    "window = timedelta(minutes=window_minutes)\n",
    "window_sec = window.total_seconds()\n",
    "\n",
    "# Convert to seconds array for fast search\n",
    "tsec = df[\"timestamp\"].dt.total_seconds().to_numpy()\n",
    "\n",
    "# Generate start times for windows (in seconds)\n",
    "start_min = tsec.min()\n",
    "end_max = tsec.max()\n",
    "if end_max - start_min < window_sec:\n",
    "    # If the stream is shorter than the window, use one window\n",
    "    start_grid = np.array([start_min], dtype=float)\n",
    "else:\n",
    "    start_grid = np.arange(start_min, end_max - window_sec + 1, slide_seconds, dtype=float)\n",
    "\n",
    "# Count comments in each window using searchsorted (O(N log N))\n",
    "starts_idx = np.searchsorted(tsec, start_grid, side=\"left\")\n",
    "ends_idx = np.searchsorted(tsec, start_grid + window_sec, side=\"left\")\n",
    "counts = ends_idx - starts_idx\n",
    "rates = counts / window_minutes\n",
    "\n",
    "threshold = avg_comments_per_minute * threshold_multiplier\n",
    "spike_mask = rates > threshold\n",
    "\n",
    "# Build segments (merge contiguous/overlapping windows into longer segments)\n",
    "segments = []\n",
    "current_start = None\n",
    "current_end = None\n",
    "\n",
    "for sg, is_spike in zip(start_grid, spike_mask):\n",
    "    s = pd.to_timedelta(sg, unit=\"s\")\n",
    "    e = s + window\n",
    "    if is_spike:\n",
    "        if current_start is None:\n",
    "            current_start, current_end = s, e\n",
    "        else:\n",
    "            # If this window overlaps/touches the previous, extend\n",
    "            if s <= current_end:\n",
    "                current_end = max(current_end, e)\n",
    "            else:\n",
    "                segments.append((current_start, current_end))\n",
    "                current_start, current_end = s, e\n",
    "    else:\n",
    "        if current_start is not None:\n",
    "            segments.append((current_start, current_end))\n",
    "            current_start, current_end = None, None\n",
    "\n",
    "# Flush last open segment\n",
    "if current_start is not None:\n",
    "    segments.append((current_start, current_end))\n",
    "\n",
    "# --- Output ---\n",
    "print(\"Highlight Segments:\")\n",
    "for seg in segments:\n",
    "    print(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837fedd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import os\n",
    "import pandas as pd\n",
    "import time #time.sleep(60) between requests if you hit rate limits\n",
    "\n",
    "def gen_caption(video_file_name=\"USC_NOIS_CLIPS/clip1.mp4\", model=\"models/gemini-2.5-flash-lite\", max_comments=2, comment=\"its dabover\"):\n",
    "    # Only for videos of size <20Mb\n",
    "    video_bytes = open(video_file_name, 'rb').read() #the sports clip \n",
    "    client = genai.Client() #set conda env variable GOOGLE_API_KEY to your API key\n",
    "    response = client.models.generate_content(\n",
    "        model=model,\n",
    "        contents=types.Content(\n",
    "            parts=[\n",
    "                types.Part(\n",
    "                    inline_data=types.Blob(data=video_bytes, mime_type='video/mp4')\n",
    "                ),\n",
    "                types.Part(text=f'Ignore all non sports knowledge Act like a really funny sports analyst. Be Concise. Begin by stating the game time and quarter then. Analyze this college football clip: Describe the key plays, player actions, and which team gained momentum. Note any turnovers or big gains. Finally announce this {comment} sent by anonomous fan in a humorous way.')\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1a63bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=11>\n",
      ") candidates=[Candidate(\n",
      "  content=Content(\n",
      "    parts=[\n",
      "      Part(\n",
      "        text=\"\"\"Alright, it's the second quarter with :49 seconds left on the clock, and we've got a classic Big Noon Saturday matchup brewing! USC's Trojans are trailing the Illinois Fighting Illini 14-7.\n",
      "\n",
      "It looks like Illinois tried to punch it in from the one-yard line, but a flag comes out. It appears to be a holding penalty, which is going to push them back. That's a real bummer for the Illini, who were trying to extend their lead.\n",
      "\n",
      "Then, we see a scramble for the ball, and it looks like USC might have recovered! It's chaos out there, folks! The USC players are fired up, and you can see them celebrating. This turnover has definitely shifted the momentum in favor of the Trojans. They've got a chance to tie this thing up before the half.\n",
      "\n",
      "And that's a wrap on this clip, sent in by an anonymous fan. Looks like this one's a DABOVER!\"\"\"\n",
      "      ),\n",
      "    ],\n",
      "    role='model'\n",
      "  ),\n",
      "  finish_reason=<FinishReason.STOP: 'STOP'>,\n",
      "  index=0\n",
      ")] create_time=None model_version='gemini-2.5-flash-lite' prompt_feedback=None response_id='48jYaPmyI6PUjMcPotyykQE' usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  cache_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.VIDEO: 'VIDEO'>,\n",
      "      token_count=16966\n",
      "    ),\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=67\n",
      "    ),\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.AUDIO: 'AUDIO'>,\n",
      "      token_count=2059\n",
      "    ),\n",
      "  ],\n",
      "  cached_content_token_count=19092,\n",
      "  candidates_token_count=206,\n",
      "  prompt_token_count=19534,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=69\n",
      "    ),\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.VIDEO: 'VIDEO'>,\n",
      "      token_count=17358\n",
      "    ),\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.AUDIO: 'AUDIO'>,\n",
      "      token_count=2107\n",
      "    ),\n",
      "  ],\n",
      "  total_token_count=19740\n",
      ") automatic_function_calling_history=[] parsed=None\n"
     ]
    }
   ],
   "source": [
    "print(gen_caption(model=\"models/gemini-2.5-flash-lite\", max_comments=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67e4573",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of every file in directory\n",
    "video_paths = []\n",
    "for filename in os.listdir('USC_NOIS_CLIPS'):\n",
    "    video_file_name = f'USC_NOIS_CLIPS/{filename}'\n",
    "    video_paths.append(video_file_name)\n",
    "\n",
    "comments = []\n",
    "\n",
    "\n",
    "df = pd.DataFrame(video_paths, columns=['video_path'])\n",
    "df['comment'] = comments\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    video_path = row['video_path']\n",
    "    comment = row['comment']\n",
    "    print(f'Generating caption for {video_path} with comment {comment}')\n",
    "    response = gen_caption(video_file_name=video_path, comment=comment)\n",
    "    print(response)\n",
    "    time.sleep(60) # 1 minute sleep to avoid rate limits\n",
    "    df.at[index, 'response'] = str(response)\n",
    "    df.to_csv('video_comments_responses.csv', index=False) #save after each iteration\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HackGT12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
